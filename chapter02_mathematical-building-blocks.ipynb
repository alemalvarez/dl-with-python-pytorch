{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport utils\n",
    "%autoreload 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# 2. The mathematical building blocks of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 2.1 A first look at a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Listing 2.1: Loading the MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== train_images tensor info ====================\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (60000, 28, 28)\n",
      "\n",
      "==================== train_labels tensor info ====================\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (60000,)\n",
      "Content: [5 0 4 ... 5 6 8]\n",
      "\n",
      "==================== test_images tensor info ====================\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (10000, 28, 28)\n",
      "\n",
      "==================== test_labels tensor info ====================\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (10000,)\n",
      "Content: [7 2 1 ... 4 5 6]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# In Keras over TensorFlow, MNIST data gets loaded as numpy arrays.\n",
    "utils.tensor_info(train_images, \"train_images\")\n",
    "utils.tensor_info(train_labels, \"train_labels\")\n",
    "utils.tensor_info(test_images, \"test_images\")\n",
    "utils.tensor_info(test_labels, \"test_labels\")\n",
    "\n",
    "# Draw first 9 images:\n",
    "utils.draw_grid(train_images[:10], train_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== train_dataloader tensor info ====================\n",
      "Type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Batch size: 128\n",
      "Shape of features in first batch: torch.Size([128, 1, 28, 28])\n",
      "Shape of labels in first batch: torch.Size([128]) torch.int64\n",
      "\n",
      "==================== test_dataloader tensor info ====================\n",
      "Type: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Batch size: 128\n",
      "Shape of features in first batch: torch.Size([128, 1, 28, 28])\n",
      "Shape of labels in first batch: torch.Size([128]) torch.int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# PyTorch has objects Dataset to hold the samples and labels, and DataLoader to iterate easily.\n",
    "training_data = MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "# Dataloaders support automatic batching!\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_data = MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "utils.tensor_info(train_dataloader, \"train_dataloader\")\n",
    "utils.tensor_info(test_dataloader, \"test_dataloader\")\n",
    "# They are identical as both work in 128-sized batches.\n",
    "# Dimension corresponds to [Samples, Color, Height, Width]\n",
    "\n",
    "# Draw first nine images from first batch. I could iterate directly over the dataset, but didn't feel like it:\n",
    "X, y = next(iter(train_dataloader))\n",
    "utils.draw_grid(X[:10], [label.item() for label in y[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Listing 2.2: The network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# Keras is very straightforward!\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"), # 512 units, ReLU activation\n",
    "    layers.Dense(10, activation=\"softmax\") # 10 units, softmax activation (one-hot encoded label)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (1, 512)                  401920    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (1, 10)                   5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model and print the summary\n",
    "model.build(input_shape=(1,28*28))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# In PyTorch, models inherit from nn.Module. We define the layers in the constructor and the forward\n",
    "# prop in the function forward. More verbose but easier to customize.\n",
    "class TorchModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.flatten = nn.Flatten() # Transforms the 28x28 image into a 1D tensor\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512), # 512 units\n",
    "            nn.ReLU(), # ReLU activation\n",
    "            nn.Linear(512, 10) # 10 units\n",
    "        )\n",
    "    \n",
    "    def forward(self, x): # Forward prop\n",
    "        x = self.flatten(x)\n",
    "        output = self.stack(x)\n",
    "        return F.log_softmax(output, dim=1) # Log-softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 512]         401,920\n",
      "              ReLU-3                  [-1, 512]               0\n",
      "            Linear-4                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 1.55\n",
      "Estimated Total Size (MB): 1.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Torchsummary prints very similar information to Keras summary()\n",
    "torchmodel = TorchModel() # Instantiate the model\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(torchmodel, input_size=(1, 28*28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Listing 2.3: The compilation step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, Keras is pretty straightforward here.\n",
    "model.compile( # Compile the model with the optimizer, loss function and metrics\n",
    "    optimizer='rmsprop',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch # Import PyTorch\n",
    "\n",
    "# Define RMSprop optimizer\n",
    "optimizer = optim.RMSprop(torchmodel.parameters())\n",
    "\n",
    "# Define loss function (CrossEntropyLoss for integer labels)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(train_dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for X, y in train_dataloader: # Iterate over batches \n",
    "        # Compute prediction error\n",
    "        y_hat = model(X)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # Set gradients to zero\n",
    "        loss.backward() # Compute gradient\n",
    "        optimizer.step() # Update weights\n",
    "\n",
    "        # Accumulate loss and calculate accuracy\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (torch.argmax(y_hat, dim=1) == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "\n",
    "    # Calculate overall average loss and accuracy\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Listing 2.4: Preparing the image data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "# In tf, we used the numpy array operation reshape and divided by the scalar 255\n",
    "# so that all values go between 0 and 1.\n",
    "# The MNIST dataset loaded in PyTorch is already normalized, and it gets flattened\n",
    "# in the input of the neural network.\n",
    "train_images = train_images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Listing 2.5: \"Fitting\" the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2539 - accuracy: 0.9268\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1027 - accuracy: 0.9689\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9796\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0493 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0367 - accuracy: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x353dbf990>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Average Loss: 0.7177, Accuracy: 0.9213\n",
      "Epoch 2/5\n",
      "Average Loss: 0.1341, Accuracy: 0.9610\n",
      "Epoch 3/5\n",
      "Average Loss: 0.0979, Accuracy: 0.9717\n",
      "Epoch 4/5\n",
      "Average Loss: 0.0834, Accuracy: 0.9766\n",
      "Epoch 5/5\n",
      "Average Loss: 0.0696, Accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "# Manually write the loop in PyTorch!\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    avg_loss, accuracy = train(train_dataloader, torchmodel, criterion, optimizer)\n",
    "    print(f\"Average Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Listing 2.6: Using the model to make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "==================== Keras predictions tensor info ====================\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (1, 10) | nDim: 2\n",
      "Content: [[3.8189512e-13 8.6459778e-08 3.3032735e-10 1.3274742e-09 9.9998033e-01\n",
      "  2.6420630e-09 3.7154491e-11 2.6896871e-06 1.8501319e-07 1.6572934e-05]]\n",
      "\n",
      "==================== PyTorch predictions tensor info ====================\n",
      "Type: <class 'torch.Tensor'>\n",
      "Shape: torch.Size([1, 10])\n",
      "Content: tensor([[1.9391e-24, 5.6546e-15, 7.8008e-18, 6.0084e-19, 1.0000e+00, 1.8967e-18,\n",
      "         3.0833e-25, 3.7299e-10, 1.1013e-17, 1.2760e-08]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_image = test_images[42].reshape(1, 28*28)\n",
    "test_label = test_labels[42]\n",
    "\n",
    "# Keras: predict() method returns the probabilities of each class.\n",
    "keras_prediction = model.predict(test_image)\n",
    "utils.tensor_info(keras_prediction, \"Keras predictions\")\n",
    "\n",
    "#PyTorch: torch.softmax() returns the probabilities of each class.\n",
    "test_images_tensor = torch.tensor(test_image) # Convert numpy array to PyTorch tensor\n",
    "torchmodel.eval() # Set the model to evaluation mode\n",
    "with torch.no_grad(): \n",
    "    logits = torchmodel(test_images_tensor) # Compute the logits without gradient tracking\n",
    "\n",
    "torch_prediction = torch.softmax(logits, dim=1) \n",
    "utils.tensor_info(torch_prediction, \"PyTorch predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras predicts: 4. PyTorch predicts: 4. The label is 4.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Keras predicts: {keras_prediction.argmax()}. PyTorch predicts: {torch_prediction.argmax()}. The label is {test_label}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Listing 2.7: Evaluating the model on new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 795us/step - loss: 0.0726 - accuracy: 0.9791\n",
      "test_acc: 0.9790999889373779\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Test Loss: 0.0013767263982277654\n",
      "Test Accuracy: 0.9655\n"
     ]
    }
   ],
   "source": [
    "torchmodel.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        y_hat = torchmodel(X) # Compute the predictions\n",
    "        loss = criterion(y_hat, y) # Compute the loss\n",
    "        test_loss += loss.item() # Accumulate the loss\n",
    "\n",
    "        # For accuracy, we need to count the number of correct predictions\n",
    "        predicted = torch.argmax(y_hat, 1) # Get the predicted class\n",
    "        total_predictions += y.size(0) # Accumulate the number of samples\n",
    "        correct_predictions += (predicted == y).sum().item()\n",
    "\n",
    "test_loss /= len(test_dataloader.dataset)\n",
    "test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Avg. Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Evaluating Keras model 'sequential_2' ====================\n",
      "Test loss: 0.07256974279880524 | Test accuracy: 0.9790999889373779\n",
      "==================== Evaluating Pytorch model 'TorchModel' =================\n",
      "Test loss: 0.0013767263982277654 | Test accuracy: 0.9655\n"
     ]
    }
   ],
   "source": [
    "# We can also use the awful utils.py file to do this for us.\n",
    "utils.model_eval(model, test_images, test_labels)\n",
    "utils.model_eval(torchmodel, test_dataloader, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 2.2 Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Scalars (rank-0 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Numpy scalar tensor info ====================\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: () | nDim: 0\n",
      "Content: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "utils.tensor_info(x, \"Numpy scalar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== PyTorch scalar tensor info ====================\n",
      "Type: <class 'torch.Tensor'>\n",
      "Shape: torch.Size([])\n",
      "Content: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(12)\n",
    "utils.tensor_info(x, \"PyTorch scalar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== TensorFlow scalar tensor info ====================\n",
      "Type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Shape: ()\n",
      "Content: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.constant(12)\n",
    "utils.tensor_info(x, \"TensorFlow scalar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vectors (rank-1 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Matrices (rank-2 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Rank-3 and higher-rank tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Key attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Displaying the fourth digit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_labels[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Manipulating tensors in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 14:, 14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The notion of data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Real-world examples of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Timeseries data or sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Video data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The gears of neural networks: tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "y = np.expand_dims(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Geometric interpretation of tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A geometric interpretation of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The engine of neural networks: gradient-based optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### What's a derivative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Derivative of a tensor operation: the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Chaining derivatives: The Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Automatic differentiation with computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The gradient tape in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(0.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Looking back at our first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Reimplementing our first example from scratch in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Dense class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "           x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "       weights = []\n",
    "       for layer in self.layers:\n",
    "           weights += layer.weights\n",
    "       return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Running one training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The full training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter02_mathematical-building-blocks.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
